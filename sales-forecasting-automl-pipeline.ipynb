{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ee2251c2-06cb-4179-9a35-3d42fe2a27c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated property [core/project].\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = 'sk-ai-ml-poc'  # <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' \n",
    "!gcloud config set project {PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6718cf38-b836-43ae-84ac-da6df463cc9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# New\n",
    "! pip3 install -U google-cloud-storage $USER_FLAG\n",
    "# ! pip3 install $USER kfp google-cloud-pipeline-components --upgrade\n",
    "!git clone https://github.com/kubeflow/pipelines.git\n",
    "!pip install pipelines/components/google-cloud/.\n",
    "!pip install google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b518ddbb-40e7-4ff5-993f-9b38fa4c7c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Automatically restart kernel after installs\n",
    "import IPython\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "cf7e0df1-f068-4069-9ae4-4f04b480e552",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KFP SDK version: 1.8.10\n",
      "google_cloud_pipeline_components version: 0.2.3.dev\n"
     ]
    }
   ],
   "source": [
    "! python3 -c \"import kfp; print('KFP SDK version: {}'.format(kfp.__version__))\"\n",
    "! python3 -c \"import google_cloud_pipeline_components; print('google_cloud_pipeline_components version: {}'.format(google_cloud_pipeline_components.__version__))\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b65853a4-f5cc-4ce6-a338-d1e902c0422f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: GOOGLE_CLOUD_PROJECT=sk-ai-ml-poc\n"
     ]
    }
   ],
   "source": [
    "# GCP Project Configuration:\n",
    "# project where pipeline and vertex jobs are executed\n",
    "\n",
    "PROJECT_ID = 'sk-ai-ml-poc' # {type: 'string'} <--- TODO: CHANGE THIS\n",
    "PROJECT_NUMBER = '555195908111' # {type: 'string'} <--- TODO: CHANGE THIS\n",
    "LOCATION = 'us-central1' # {type: 'string'} \n",
    "BQ_LOCATION = 'us-central1' # {type: 'string'}\n",
    "\n",
    "SCOPES = (\n",
    "  'https://www.googleapis.com/auth/cloud-platform',\n",
    ")\n",
    "\n",
    "assert LOCATION, 'the value for this variable must be set'\n",
    "assert PROJECT_ID, 'the value for this variable must be set'\n",
    "assert PROJECT_NUMBER, 'the value for this variable must be set'\n",
    "%env GOOGLE_CLOUD_PROJECT={PROJECT_ID}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86725999-25a2-43b9-b56b-87c96444c432",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GS_PIPELINE_ROOT_PATH: gs://sk-forecasting/pipeline_root/skewalramani\n"
     ]
    }
   ],
   "source": [
    "# Required Pipeline Parameters\n",
    "USER = 'skewalramani'  #  {type: 'string'} <--- TODO: CHANGE THIS\n",
    "BUCKET_NAME = 'sk-forecasting'  #  {type: 'string'} <--- TODO: CHANGE THIS\n",
    "GS_PIPELINE_ROOT_PATH = 'gs://{}/pipeline_root/{}'.format(BUCKET_NAME, USER)\n",
    "\n",
    "\n",
    "print('GS_PIPELINE_ROOT_PATH: {}'.format(GS_PIPELINE_ROOT_PATH))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad0374ec-2d7a-4bba-b353-496439818bc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import json\n",
    "import os\n",
    "import time\n",
    "from typing import Any, Callable, Dict, NamedTuple, Optional\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from google import auth\n",
    "from google.api_core import exceptions as google_exceptions\n",
    "from google_cloud_pipeline_components import aiplatform as gcc_aip\n",
    "from google_cloud_pipeline_components.experimental import forecasting as gcc_aip_forecasting\n",
    "import google.cloud.aiplatform\n",
    "from google.cloud import bigquery\n",
    "from google.cloud import storage\n",
    "\n",
    "#from google.colab import auth as colab_auth\n",
    "#from google.colab import drive\n",
    "\n",
    "import kfp\n",
    "import kfp.v2.dsl\n",
    "from kfp.v2.google import client as pipelines_client\n",
    "\n",
    "from matplotlib import dates as mdates\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "from IPython.display import Image\n",
    "from IPython.core.display import HTML "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5eb4baf5-fb67-4e9f-bb29-c7580ae87fad",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aiplatform SDK version: 1.8.1\n"
     ]
    }
   ],
   "source": [
    "print(f'aiplatform SDK version: {google.cloud.aiplatform.__version__}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "61fbcb0e-ecd1-4949-a59a-0670edfb6de7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# authenticate_user()\n",
    "credentials, _ = auth.default()\n",
    "credentials, _ = auth.default(scopes=SCOPES, quota_project_id=PROJECT_ID)\n",
    "bq_client = bigquery.Client(project=PROJECT_ID, credentials=credentials)\n",
    "pipeline_client = pipelines_client.AIPlatformClient(\n",
    "  project_id=PROJECT_ID,\n",
    "  region=LOCATION,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c3365ed6-c4e5-4e24-ac3c-bb1c36cef270",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINES = {}\n",
    "\n",
    "PIPELINES_FILEPATH = 'gs://sk-forecasting/pipelines/pipelines.json'\n",
    "\n",
    "if os.path.isfile(PIPELINES_FILEPATH):\n",
    "  with open(PIPELINES_FILEPATH) as f:\n",
    "    PIPELINES = json.load(f)\n",
    "else:\n",
    "  PIPELINES = {}\n",
    "\n",
    "def save_pipelines():\n",
    "  with open(PIPELINES_FILEPATH, 'w') as f:\n",
    "    json.dump(PIPELINES, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "7559286d-277f-445a-a1e2-ac2b998df408",
   "metadata": {},
   "outputs": [],
   "source": [
    "@kfp.v2.dsl.component(base_image='python:3.9')\n",
    "def create_input_table_specs(\n",
    "  sales_table_uri: str,\n",
    "  time_granularity_unit: str,\n",
    "  time_granularity_quantity: int,\n",
    ") -> NamedTuple(\n",
    "  'Output',\n",
    "  [('input_table_specs', str), ('model_feature_columns', str)],\n",
    "):\n",
    "  import json\n",
    "\n",
    "  sales_table_specs = {\n",
    "    'bigquery_uri': sales_table_uri,\n",
    "    'table_type': 'FORECASTING_PRIMARY',\n",
    "    'forecasting_primary_table_metadata': {\n",
    "        'time_column': 'ds',\n",
    "        'target_column': 'y',\n",
    "        'time_series_identifier_columns': ['xsku', 'xstore'],\n",
    "        'unavailable_at_forecast_columns': [],\n",
    "        'time_granularity': {\n",
    "          'unit': time_granularity_unit,\n",
    "          'quantity': time_granularity_quantity,\n",
    "        },\n",
    "        # 'predefined_splits_column': 'ml_use',\n",
    "        # 'predefined_split_column': 'ml_use', # model_override\n",
    "    }\n",
    "  }\n",
    "\n",
    "\n",
    "  model_feature_columns = [\n",
    "    'cal_name',\n",
    "    'cal_val',\n",
    "    'discount_amount',\n",
    "    'ds',\n",
    "    'oss_Days',\n",
    "    'promo_type',\n",
    "    'wic',\n",
    "    'xclass',\n",
    "    'xcoupon_type',\n",
    "    'xdiscount_type',\n",
    "    'xsku',\n",
    "    'xstore',\n",
    "    'xstore_type',\n",
    "    'xsubclass',\n",
    "    'y'\n",
    "  ]\n",
    "\n",
    "  input_table_specs = [\n",
    "    sales_table_specs\n",
    "\n",
    "  ]\n",
    "\n",
    "  return (\n",
    "    json.dumps(input_table_specs),  # input_table_specs\n",
    "    json.dumps(model_feature_columns),  # model_feature_columns\n",
    "  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0fdde576-e37c-4845-8f79-76534cf1f27a",
   "metadata": {},
   "outputs": [],
   "source": [
    "OVERRIDE = 'True' # replace BQ eval tables?\n",
    "VERSION = 'sales_v1' # <--- TODO; Pipeline & model identifier;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8b45385b-1c0d-4380-aa7f-7440d8fc88a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "PIPELINE_TAG = 'train-sales-ds' # <--- TODO; optionally name pipeline\n",
    "@kfp.v2.dsl.pipeline(\n",
    "  name=f'{VERSION}-{PIPELINE_TAG}'.replace('_', '-')\n",
    ")\n",
    "def pipeline(\n",
    "  vertex_project: str,\n",
    "  location: str,\n",
    "  version: str,\n",
    "  data_source_dataset: str,\n",
    "  sales_table_uri: str,\n",
    "  time_granularity_unit: str,\n",
    "  time_granularity_quantity: int,\n",
    "  context_window: int,\n",
    "  forecast_horizon: int,\n",
    "  override: str,\n",
    "  budget_milli_node_hours: int = 16000,\n",
    "):\n",
    "\n",
    "\n",
    "  create_input_table_specs_op = create_input_table_specs(\n",
    "    sales_table_uri=sales_table_uri,\n",
    "    time_granularity_unit=time_granularity_unit,\n",
    "    time_granularity_quantity=time_granularity_quantity\n",
    "   )\n",
    "#  create_input_table_specs_op.after(create_dataset_op)\n",
    "\n",
    "  forecasting_validation_op = gcc_aip_forecasting.ForecastingValidationOp(\n",
    "    input_tables=create_input_table_specs_op.outputs['input_table_specs'],\n",
    "    validation_theme='FORECASTING_TRAINING',\n",
    "  )\n",
    "\n",
    "  forecasting_preprocessing_op = gcc_aip_forecasting.ForecastingPreprocessingOp(\n",
    "    project=vertex_project,\n",
    "    input_tables=create_input_table_specs_op.outputs['input_table_specs'],\n",
    "    preprocessing_bigquery_dataset=data_source_dataset,\n",
    "  )\n",
    "  forecasting_preprocessing_op.after(forecasting_validation_op)\n",
    "\n",
    "  \n",
    "  prepare_data_for_train_op = gcc_aip_forecasting.ForecastingPrepareDataForTrainOp(\n",
    "      input_tables=(\n",
    "          create_input_table_specs_op.outputs['input_table_specs']\n",
    "      ),\n",
    "      preprocess_metadata=(\n",
    "          forecasting_preprocessing_op.outputs['preprocess_metadata']\n",
    "      ),\n",
    "      model_feature_columns=(\n",
    "          create_input_table_specs_op.outputs['model_feature_columns']\n",
    "      ),\n",
    "    )\n",
    "\n",
    "\n",
    "  time_series_dataset_create_op = gcc_aip.TimeSeriesDatasetCreateOp(\n",
    "    display_name='sales_training_dataset', \n",
    "    bq_source=prepare_data_for_train_op.outputs['preprocess_bq_uri'],\n",
    "    project=vertex_project,\n",
    "    location=location,\n",
    "  )\n",
    "\n",
    "#  mape_model_version = f'{VERSION}-seq2seq-mape' # TODO: determines model display name and eval BQ table name # f'{VERSION}-l2l-mape'\n",
    "  rmse_model_version = f'{VERSION}-seq2seq-rmse' # TODO: determines model display name and eval BQ table name\n",
    "\n",
    "\n",
    "\n",
    "  rmse_model_op = gcc_aip_forecasting.ForecastingTrainingWithExperimentsOp(\n",
    "      display_name=f'train-{rmse_model_version}',\n",
    "      model_display_name=rmse_model_version,\n",
    "      model_labels={'model_override' : 'se2seq-hier'}, # model_override : se2seq-hier, tft\n",
    "      # model_labels={'model_type' : 'l2l'},\n",
    "      dataset=time_series_dataset_create_op.outputs['dataset'],\n",
    "      context_window=context_window,\n",
    "      forecast_horizon=forecast_horizon,\n",
    "      budget_milli_node_hours=budget_milli_node_hours,\n",
    "      project=vertex_project,\n",
    "      location=location,\n",
    "      export_evaluated_data_items=True,\n",
    "      #export_evaluated_data_items_bigquery_destination_uri=get_eval_dataset_path_uri_op.outputs['model_2_bigquery_table_uri'], # must be format: ``bq://<project_id>:<dataset_id>:<table>``\n",
    "      export_evaluated_data_items_override_destination=True,\n",
    "      target_column=prepare_data_for_train_op.outputs['target_column'],\n",
    "      time_column=prepare_data_for_train_op.outputs['time_column'],\n",
    "      time_series_identifier_column=prepare_data_for_train_op.outputs['time_series_identifier_column'],\n",
    "      time_series_attribute_columns=prepare_data_for_train_op.outputs['time_series_attribute_columns'],\n",
    "      unavailable_at_forecast_columns=prepare_data_for_train_op.outputs['unavailable_at_forecast_columns'],\n",
    "      available_at_forecast_columns=prepare_data_for_train_op.outputs['available_at_forecast_columns'],\n",
    "      data_granularity_unit=prepare_data_for_train_op.outputs['data_granularity_unit'],\n",
    "      data_granularity_count=prepare_data_for_train_op.outputs['data_granularity_count'],\n",
    "      predefined_split_column_name= '', # prepare_data_for_train_op.outputs['predefined_split_column'],\n",
    "      column_transformations=prepare_data_for_train_op.outputs['column_transformations'],\n",
    "      weight_column=prepare_data_for_train_op.outputs['weight_column'],\n",
    "      optimization_objective='minimize-rmse',\n",
    "      additional_experiments={\n",
    "          'forecasting_model_type_override': 'seq2seq',\n",
    "          'forecasting_hierarchical_group_column_names':'xksu, xstore'},\n",
    "  )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a308bf8e-2621-4a9e-ba97-e20138d5bf0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfp.v2.compiler.Compiler().compile(\n",
    "  pipeline_func=pipeline, \n",
    "  package_path='sales_fsct_pipeline_spec.json',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "df59e1af-e198-4d80-994d-6d0df2bcc6af",
   "metadata": {},
   "outputs": [],
   "source": [
    "PROJECT_ID = 'sk-ai-ml-poc' # <--- TODO: If not set\n",
    "LOCATION = 'us-central1' # <--- TODO: If not set\n",
    "location = 'us-central1' # <--- TODO: If not set\n",
    "bq_location = 'us-central1' # <--- TODO: If not set\n",
    "\n",
    "\n",
    "# BQ dataset for source data source\n",
    "DATA_SOURCE_DATASET = 'h_data_1'\n",
    "\n",
    "\n",
    "# training BQ tables\n",
    "SALES_TABLE = 'sk-ai-ml-poc.h_data_1.train_data_1'  #  {type: 'string'} <---TODO: CHANGE THIS\n",
    "\n",
    "\n",
    "# TODO: Forecasting Configuration:\n",
    "HISTORY_WINDOW_n = 26 #  {type: 'integer'} # context_window\n",
    "FORECAST_HORIZON = 26 #  {type: 'integer'} \n",
    "BUDGET_MILLI_NODE_HOURS = 1000\n",
    "\n",
    "\n",
    "\n",
    "assert HISTORY_WINDOW_n, 'the value for this variable must be set'\n",
    "assert FORECAST_HORIZON, 'the value for this variable must be set'\n",
    "assert LOCATION, 'the value for this variable must be set'\n",
    "assert PROJECT_ID, 'the value for this variable must be set'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "dc5c960d-ff94-45d4-9e53-6ced9fd7b3d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "overwrite = True # True creates new pipeline instance for execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e00be1e8-7c29-4a9e-ac2b-3b62cd69c0b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "See the Pipeline job <a href=\"https://console.cloud.google.com/vertex-ai/locations/us-central1/pipelines/runs/sales-v1-train-sales-ds-20220128133552?project=sk-ai-ml-poc\" target=\"_blank\" >here</a>."
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "if not PIPELINES.get('train') or overwrite:\n",
    "  response = pipeline_client.create_run_from_job_spec(\n",
    "    job_spec_path='sales_fsct_pipeline_spec.json',\n",
    "    # service_account=SERVICE_ACCOUNT, # <--- TODO: Uncomment if needed\n",
    "    parameter_values={\n",
    "      'vertex_project': PROJECT_ID,\n",
    "      'location': LOCATION,\n",
    "      'version': VERSION,\n",
    "      'data_source_dataset': DATA_SOURCE_DATASET,\n",
    "      'sales_table_uri': f'bq://{SALES_TABLE}',  \n",
    "      'time_granularity_unit': 'WEEK',\n",
    "      'time_granularity_quantity': 1,\n",
    "      'context_window': HISTORY_WINDOW_n,\n",
    "      'forecast_horizon': FORECAST_HORIZON,\n",
    "      'override': OVERRIDE,\n",
    "      'budget_milli_node_hours': BUDGET_MILLI_NODE_HOURS,\n",
    "    },\n",
    "    pipeline_root=f'{GS_PIPELINE_ROOT_PATH}/{VERSION}',\n",
    "  )\n",
    "  PIPELINES['train'] = response['name']\n",
    "  # save_pipelines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56e36f10-23e0-4741-b369-67819428ee7a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "python3",
   "name": "common-cpu.m87",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/base-cpu:m87"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
