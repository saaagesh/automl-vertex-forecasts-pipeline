{"cells": [{"cell_type": "code", "execution_count": 3, "metadata": {}, "outputs": [], "source": "#!/usr/bin/python\n\"\"\"BigQuery I/O PySpark example.\"\"\"\nfrom pyspark.sql import SparkSession\n\nspark = SparkSession \\\n  .builder \\\n  .appName('spark-bigquery-demo') \\\n  .config('spark.jars','gs://spark-lib/bigquery/spark-bigquery-with-dependencies_2.12-0.23.2.jar') \\\n  .getOrCreate()"}, {"cell_type": "code", "execution_count": 4, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "root\n |-- datehour: timestamp (nullable = true)\n |-- wiki: string (nullable = true)\n |-- title: string (nullable = true)\n |-- views: long (nullable = true)\n\n"}], "source": "table = \"bigquery-public-data.wikipedia.pageviews_2020\"\ndf = spark.read \\\n  .format(\"bigquery\") \\\n  .option(\"table\", table) \\\n  .load()\ndf.printSchema()"}, {"cell_type": "code", "execution_count": 5, "metadata": {}, "outputs": [{"name": "stdout", "output_type": "stream", "text": "+---------+----------+\n|     word|word_count|\n+---------+----------+\n|     XVII|         2|\n|    spoil|        28|\n|    Drink|         7|\n|forgetful|         5|\n|   Cannot|        46|\n|    cures|        10|\n|   harder|        13|\n|  tresses|         3|\n|      few|        62|\n|  steel'd|         5|\n| tripping|         7|\n|   travel|        35|\n|   ransom|        55|\n|     hope|       366|\n|       By|       816|\n|     some|      1169|\n|    those|       508|\n|    still|       567|\n|      art|       893|\n|    feign|        10|\n+---------+----------+\nonly showing top 20 rows\n\nroot\n |-- word: string (nullable = false)\n |-- word_count: long (nullable = true)\n\n"}], "source": "\n# Use the Cloud Storage bucket for temporary BigQuery export data used\n# by the connector.\nbucket = \"sk-dataproc-processing\"\nspark.conf.set('temporaryGcsBucket', bucket)\n\n# Load data from BigQuery.\nwords = spark.read.format('bigquery') \\\n  .option('table', 'bigquery-public-data:samples.shakespeare') \\\n  .load()\nwords.createOrReplaceTempView('words')\n\n# Perform word count.\nword_count = spark.sql(\n    'SELECT word, SUM(word_count) AS word_count FROM words GROUP BY word')\nword_count.show()\nword_count.printSchema()\n\n\n"}, {"cell_type": "markdown", "metadata": {}, "source": "## Create a BQ dataset \"wordcount_dataset\" before running the write query"}, {"cell_type": "code", "execution_count": 7, "metadata": {}, "outputs": [], "source": "# Saving the data to BigQuery\nword_count.write.format('bigquery') \\\n  .option('table', 'wordcount_dataset.wordcount_output') \\\n  .save()"}, {"cell_type": "code", "execution_count": null, "metadata": {}, "outputs": [], "source": ""}], "metadata": {"kernelspec": {"display_name": "Python 3", "language": "python", "name": "python3"}, "language_info": {"codemirror_mode": {"name": "ipython", "version": 3}, "file_extension": ".py", "mimetype": "text/x-python", "name": "python", "nbconvert_exporter": "python", "pygments_lexer": "ipython3", "version": "3.7.4"}}, "nbformat": 4, "nbformat_minor": 4}